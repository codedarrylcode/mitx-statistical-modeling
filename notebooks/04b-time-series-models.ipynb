{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series: Statistical Models & Fitting\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recap**<br>\n",
    "\n",
    "Weak stationarity is defined as:\n",
    "\n",
    "1. Mean, variance independent of $t$: $\\mu_X (t) = \\mu$, $var_X (t) = var_X$\n",
    "\n",
    "2. Autocovariance is just a function of the time distance, *e.g. autocovariance between Jan and Feb should be the same as Oct and Nov*: $\\gamma_X (s, t) = \\gamma(\\lvert s - t \\rvert)$\n",
    "\n",
    "To check for stationarity, under appropriate technical conditions, the distribution of the estimator is:\n",
    "\n",
    "$\\hat\\gamma_W (h) \\sim N(0, \\frac{\\sigma_W^2}{n})$\n",
    "\n",
    "which means that the autocovariance, for $h > 0$ is expected to be close to zero if the series is stationary. If the autocovariance function does not decay to zero at all, or decays to zero very slowly, it is an indication of nonstationarity\n",
    "\n",
    "<img alt=\"Stationarity\" src=\"assets/stationarity.png\" width=\"300\">\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Model 1: Autoregressive, $AR(p)$**\n",
    "\n",
    "$X_t = \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\dots \\phi_p X_{t-p} + W_t$\n",
    "\n",
    "AR(1) means that the model will use $t-1$ time steps to predict $X_t$ by estimating $\\phi$ that minimizes the error.\n",
    "\n",
    "The model is usually not very useful for long term prediction as it converges to a constant value (the unconditional mean of the time series). To get longer term prediction, increase the time step between different measurements. For example, with daily time series data, it may be hard to predict 30 days ahead; but if we first average the daily data into weekly data then we might be able to predict the value for next month (with 4 time steps ahead). Another way is to model the trend and seasonality seperately - this will assume that the trend and seasonality will persist in the long-term.\n",
    "\n",
    "****\n",
    "\n",
    "**Model 2: Random Walk**\n",
    "\n",
    "$X_t = X_{t-1} + W_t + \\delta$ where $\\delta$ is a deterministic linear increase at each time step\n",
    "\n",
    "Essentially, this is a sum of white noise random variables:\n",
    "\n",
    "$X_t = X_{t-1} + W_t = X_{t-2} + W_{t-1} + W_t = X_0 + W_1 + \\dots + W_t$\n",
    "\n",
    "With drift (linear increase):\n",
    "\n",
    "$X_t = t \\cdot \\delta + X_0 + \\sum_{s=0}^{t} W_s$\n",
    "\n",
    "<img alt=\"Random Walk with Drift\" src=\"assets/random_walk_drifted.png\" width=\"300\">\n",
    "\n",
    "Properties:\n",
    "\n",
    "- $\\mathbb {E}[X_t] = t \\cdot \\delta + X_0$\n",
    "- without drift: $var(X_t) = t \\cdot \\sigma_w^2$\n",
    "- Not stationary, because its expectation and variance grows with $t$\n",
    "- but $\\nabla X_t = X_t - X_{t-1}$ is stationary\n",
    "- autocovariance: $\\gamma_X (s,t) = cov(X_s, X_t) = var(X_0) + \\min(s,t) \\cdot \\sigma_W^2$\n",
    "\n",
    "****\n",
    "\n",
    "**Model 3: Moving Average, $MA(q)$**\n",
    "\n",
    "Given $q$, uses the previous $q$ white noises to predict the next position:\n",
    "\n",
    "$X_t = W_t + \\theta_1 W_{t-1} + \\dots + \\theta_q W_{t+q}$\n",
    "\n",
    "Properties:\n",
    "\n",
    "- $\\mathbb {E}[X_t] = 0$\n",
    "- autocovariance $\\gamma (s, t)$ depends only on $\\lvert s - t \\rvert$ and is therefore stationary\n",
    "\n",
    "    $\\gamma_X (h) = Cov(\\sum_{j=0}^{q} \\theta_j W_{t-j}, \\sum_{k=0}^{q} \\theta_k W_{t+h-k}) = \\sum_{j = 0}^{q-h} \\theta_j \\theta_{j+h} \\sigma_W^2$\n",
    "    \n",
    "    \n",
    "- ACF reflects order: $\\gamma(s,t) = 0$ if $\\lvert s - t \\rvert > q$\n",
    "- ACF distinguishes MA and AR models where ACF goes to 0 when time distance is more than order for MA models but ACF decays exponentially as time distance increases for AR models \n",
    "\n",
    "****\n",
    "\n",
    "**Model 4: ARMA(p,q)**\n",
    "\n",
    "$X_t = \\phi_1 X_{t-1} + \\dots + \\phi_p X_{t-p} + W_t + \\theta_1 W_{t-1} + \\dots + \\theta_q W_{t-q}$\n",
    "\n",
    "**Model 5: ARIMA(p,d,q)**\n",
    "\n",
    "Additional $d$ term for differencing order in addition to autoregressive and moving average terms.\n",
    "\n",
    "****\n",
    "\n",
    "**Regression x Time series**\n",
    "\n",
    "- General model: $X_t = \\beta^T \\cdot z_t + W_t$\n",
    "- linear trend: $X_t = \\beta_1 + \\beta_2 t = W_t$\n",
    "- AR(2) model: $X_t = \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + W_t$\n",
    "- external regressors: $X_t = \\beta_1 X_{t-1} + \\beta_2 Y_t + W_t$, where $Y_t$ is an external variable\n",
    "\n",
    "Using least squares estimate: $\\min_{\\beta} \\sum_{t} (x_t - \\beta^T z_t)^2$, but errors may be correlated over time as observations are not orthogonal.\n",
    "\n",
    "How to decide which model to use? Use ACF as diagnostic tool.\n",
    "\n",
    "Example: $X_t = T_t + Y_t$, sum of\n",
    "- linear trend: $T_t = 50 + 3t$\n",
    "- AR(1) model: $Y_t = 0.8Y_{t-1} + W_t$, $\\sigma_W = 20$\n",
    "\n",
    "<img alt=\"Sample Time Series\" src=\"assets/sample_time_series.jpg\" width=\"300\">\n",
    "\n",
    "Look at largest cross-covariance terms to determine which variables to select\n",
    "\n",
    "<img alt=\"Cross Covariance\" src=\"assets/cross_covariance.jpg\" width=\"300\">\n",
    "\n",
    "Generally, follow these steps when fitting a time series:\n",
    "\n",
    "1. Transform time series to make it stationary:\n",
    "    - log-transform\n",
    "    - remove trends / seasonality\n",
    "    - differencing\n",
    "2. Check if time series looks like only white noise using ACF\n",
    "3. Otherwise, fit MA models if ACF decays exponentially or AR models if ACF decays linearly\n",
    "4. Estimate coefficients and compute residuals to test for white noise\n",
    "\n",
    "****\n",
    "\n",
    "**Parameter estimation for stationary AR(p), using Yule-Walker**\n",
    "\n",
    "Estimate parameters $\\hat\\phi$, $\\hat\\sigma_W^2$ using Yule-Walker equations: method of moments\n",
    "\n",
    "1. Estimate autocovariances $\\gamma(h)$ for $h = 0, 1, 2, \\dots$ from averages\n",
    "2. Solve system of linear equations: for $h= 1, \\dots, p$ using estimates of $\\gamma(h)$\n",
    "    \n",
    "    $\\gamma(h) = \\phi_1 \\gamma(h-1) + \\phi_2 \\gamma(h-2) + \\dots + \\phi_p \\gamma(h-p)$\n",
    "\n",
    "    $\\sigma_W^2 = \\gamma(0) - \\phi_1 \\gamma(1) - \\phi_2 \\gamma(2) - \\dots - \\phi_p \\gamma(p)$\n",
    "    \n",
    "- Yule-Walker equations in matrix form ($\\Gamma_p$) is a $p \\times p$ covariance matrix with $(i, j)$th entry is $\\gamma (i - j)$\n",
    "- Using column vectors $\\gamma_p = [\\gamma(1), \\dots, \\gamma(p)]^T$\n",
    "- Solve for $\\phi$ with this equation:\n",
    "\n",
    "    $\\gamma_p = \\Gamma_p \\phi$\n",
    "    \n",
    "    $\\phi = \\Gamma_p^{-1} \\gamma_p$\n",
    "    \n",
    "    \n",
    "- Solve for $\\sigma_W^2$ with this equation:\n",
    "\n",
    "    $\\sigma_W^2 = \\gamma(0) - \\phi_1 \\gamma(1) - \\phi_2 \\gamma(2) - \\dots - \\phi_p \\gamma(p) = \\gamma(0) - \\hat\\phi^T \\gamma_p = \\gamma(0) - \\gamma_p^T \\Gamma_p^{-1} \\gamma_p$\n",
    "\n",
    "****\n",
    "\n",
    "**Forecasting with AR(p) model**\n",
    "\n",
    "- Estimate $M$ steps into the future based on $N$  observations\n",
    "- Estimate coefficients $\\hat\\phi_1, \\dots, \\hat\\phi_p$ and plug in:\n",
    "\n",
    "    $\\hat X_{n+1} = \\hat\\phi_1 X_n + \\dots +\\hat\\phi_p X_{n-p+1}$\n",
    "    \n",
    "    $X_{n+2} = \\hat\\phi_1 \\hat X_{n+1} + \\hat\\phi_2 X_n + \\dots +\\hat\\phi_p X_{n-p+2}$\n",
    "\n",
    "    Note: When plugging in $\\hat X_{n+1}$ then we are just plugging in $\\hat\\phi_1 X_n + \\dots +\\hat\\phi_p X_{n-p+1}$\n",
    "    \n",
    "    $\\therefore$ it is always a linear combination of last $p$ observations, $X_n, \\dots, X_{n-p+1}$\n",
    "    \n",
    "    **Caution**: Only works for short horizons $m$. For long horizons, it actually converges to the mean\n",
    "    \n",
    "    <img alt=\"Convergence to the mean\" src=\"assets/converges_to_mean.jpg\" width=\"300\">\n",
    "\n",
    "****\n",
    "\n",
    "**Using Partial Autocorrelation Function, PACF, to determine order, $p$ for AR(p)**\n",
    "\n",
    "For an AR(1) model, the ACF may decay slowly to zero and does not deterministically tell us what is the order that should be applied - unlike the MA(q) model.\n",
    "\n",
    "Example: \n",
    "\n",
    "$AR(1): X_t = \\phi X_{t-1} + W_t = \\phi^2 X_{t-2} + \\phi W_{t-1} + W_t$\n",
    "\n",
    "$Corr(X_t, X_{t-2}) = Corr(\\phi^2 X_{t-2} + \\phi W_{t-1} + W_t, X_{t-2}) = \\phi^2 \\gamma(0)$\n",
    "\n",
    "\n",
    "Partial correlation of $X$, $Y$ given $Z$:\n",
    "- Regress X on Z; Y on Z\n",
    "- $\\rho_{XY \\vert Z} = corr(X - \\hat X, Y - \\hat Y)$ -- Therefore this captures the relationship of $X$, $Y$ beyond $Z$\n",
    "- Formally, the partial autocorrelation of time series $X_t$ at lag $h$ is:\n",
    "\n",
    "    $\\alpha_X (h) := Corr(X_h - \\hat X_h^{lin_{h-1}}, X_0 - \\hat X_0^{lin_{h-1}})$\n",
    "    \n",
    "    where $\\hat X_h^{lin_{h-1}}$ is the linear regression projection of $X_h$ on $X_1, \\dots, X_{h-1}$ and $\\hat X_0^{lin_{h-1}}$ is the linear regression projection of $X_0$ on $X_1, \\dots, X_{h-1}$.\n",
    "    \n",
    "    $\\therefore$ $\\alpha_X (h)$ is the correlation between $X_h$ and $X_0$ after removing the linear predictions based on the intermediate terms of the series $X_1, \\dots, X_{h-1}$\n",
    "    \n",
    "    A convenient way to compute the partial autocorrelation $\\alpha_X (h)$ is to use the Frisch-Waugh-Lovell theorem. FWL theorem says that $\\alpha_X (h)$ is the regression coefficient on regressor $X_{t-h}$ in the regression of $X_t$ along with all intermediate terms, i.e.\n",
    "    \n",
    "    $X_t = \\phi_1 X_{t-1} + \\dots + \\phi_h X_{t-h} + \\tilde X_t$\n",
    "    \n",
    "    then $\\alpha_X (h) = \\phi_h$ where the regression coefficients $\\phi_1, \\dots, \\phi_h$ can be estimated by the method of moments with Yule-Walker equations.\n",
    "    \n",
    "    \n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic code\n",
    "A `minimal, reproducible example`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
