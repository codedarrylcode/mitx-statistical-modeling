{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series: Statistical Models & Fitting\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recap**<br>\n",
    "\n",
    "Weak stationarity is defined as:\n",
    "\n",
    "1. Mean, variance independent of $t$: $\\mu_X (t) = \\mu$, $var_X (t) = var_X$\n",
    "\n",
    "2. Autocovariance is just a function of the time distance, *e.g. autocovariance between Jan and Feb should be the same as Oct and Nov*: $\\gamma_X (s, t) = \\gamma(\\lvert s - t \\rvert)$\n",
    "\n",
    "To check for stationarity, under appropriate technical conditions, the distribution of the estimator is:\n",
    "\n",
    "$\\hat\\gamma_W (h) \\sim N(0, \\frac{\\sigma_W^2}{n})$\n",
    "\n",
    "which means that the autocovariance, for $h > 0$ is expected to be close to zero if the series is stationary.\n",
    "\n",
    "<img alt=\"Stationarity\" src=\"assets/stationarity.png\" width=\"300\">\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Model 1: Autoregressive, $AR(p)$**\n",
    "\n",
    "$X_t = \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\dots \\phi_p X_{t-p} + W_t$\n",
    "\n",
    "AR(1) means that the model will use $t-1$ time steps to predict $X_t$ by estimating $\\phi$ that minimizes the error.\n",
    "\n",
    "The model is usually not very useful for long term prediction as it converges to a constant value (the unconditional mean of the time series). To get longer term prediction, increase the time step between different measurements. For example, with daily time series data, it may be hard to predict 30 days ahead; but if we first average the daily data into weekly data then we might be able to predict the value for next month (with 4 time steps ahead). Another way is to model the trend and seasonality seperately - this will assume that the trend and seasonality will persist in the long-term.\n",
    "\n",
    "****\n",
    "\n",
    "**Model 2: Random Walk**\n",
    "\n",
    "$X_t = X_{t-1} + W_t + \\delta$ where $\\delta$ is a deterministic linear increase at each time step\n",
    "\n",
    "Essentially, this is a sum of white noise random variables:\n",
    "\n",
    "$X_t = X_{t-1} + W_t = X_{t-2} + W_{t-1} + W_t = X_0 + W_1 + \\dots + W_t$\n",
    "\n",
    "With drift (linear increase):\n",
    "\n",
    "$X_t = t \\cdot \\delta + X_0 + \\sum_{s=0}^{t} W_s$\n",
    "\n",
    "<img alt=\"Random Walk with Drift\" src=\"assets/random_walk_drifted.png\" width=\"300\">\n",
    "\n",
    "Properties:\n",
    "\n",
    "- $\\mathbb {E}[X_t] = t \\cdot \\delta + X_0$\n",
    "- without drift: $var(X_t) = t \\cdot \\sigma_w^2$\n",
    "- Not stationary, because its expectation and variance grows with $t$\n",
    "- but $\\nabla X_t = X_t - X_{t-1}$ is stationary\n",
    "- autocovariance: $\\gamma_X (s,t) = cov(X_s, X_t) = var(X_0) + \\min(s,t) \\cdot \\sigma_W^2$\n",
    "\n",
    "****\n",
    "\n",
    "**Model 3: Moving Average, $MA(q)$**\n",
    "\n",
    "Given $q$, uses the previous $q$ white noises to predict the next position:\n",
    "\n",
    "$X_t = W_t + \\theta_1 W_{t-1} + \\dots + \\theta_q W_{t+q}$\n",
    "\n",
    "Properties:\n",
    "\n",
    "- $\\mathbb {E}[X_t] = 0$\n",
    "- autocovariance $\\gamma (s, t)$ depends only on $\\lvert s - t \\rvert$ and is therefore stationary\n",
    "\n",
    "    $\\gamma_X (h) = Cov(\\sum_{j=0}^{q} \\theta_j W_{t-j}, \\sum_{k=0}^{q} \\theta_k W_{t+h-k}) = \\sum_{j = 0}^{q-h} \\theta_j \\theta_{j+h} \\sigma_W^2$\n",
    "    \n",
    "    \n",
    "- ACF reflects order: $\\gamma(s,t) = 0$ if $\\lvert s - t \\rvert > q$\n",
    "- ACF distinguishes MA and AR models where ACF goes to 0 when time distance is more than order for MA models but ACF decays exponentially as time distance increases for AR models \n",
    "\n",
    "****\n",
    "\n",
    "**Model 4: ARMA(p,q)**\n",
    "\n",
    "$X_t = \\phi_1 X_{t-1} + \\dots + \\phi_p X_{t-p} + W_t + \\theta_1 W_{t-1} + \\dots + \\theta_q W_{t-q}$\n",
    "\n",
    "**Model 5: ARIMA(p,d,q)**\n",
    "\n",
    "Additional $d$ term for differencing order in addition to autoregressive and moving average terms.\n",
    "\n",
    "****\n",
    "\n",
    "**Partial Autocorrelation Function, PACF**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic code\n",
    "A `minimal, reproducible example`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
