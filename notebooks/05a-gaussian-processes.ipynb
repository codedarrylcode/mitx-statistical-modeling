{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Processes & Environmental Data\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why Environmental Data?**<br>\n",
    "\n",
    "By using data such as air/water quality, temperature and other measurements, we can do the following:\n",
    "\n",
    "- Understand underlying processes, changes (e.g. climate change, *'statistics of weather over time'*)\n",
    "- Impacts on environment, health, economics, society\n",
    "- Shape policies\n",
    "- Forecast events, warnings (*e.g. seismic network, storms, ...*)\n",
    "- Resource/energy management, *e.g. water, renewable energies*\n",
    "- Use in planning, routing, backtracking, control\n",
    "\n",
    "The underlying questions and techniques are easily transferrable to other domains. Some of the questions asked are:\n",
    "\n",
    "- Relationships (correlations, association) in temporal, spatial dimensions\n",
    "- trends; forecasting\n",
    "- planning (*e.g. where to place more sensors for better measurements*)\n",
    "- quantifying uncertainty, adaptive sensing\n",
    "\n",
    "For example, in environmental data, we'll be interested in some of these questions:\n",
    "\n",
    "- Predicting animal populations: Usually, animal populations serve as indicator of healthy ecosystems.\n",
    "\n",
    "- Predicting disease: Environmental data can provide contextual information about disease spreading. For example, how temperature changes and rainy seasons impact the spread of malaria in the tropics.\n",
    "\n",
    "- Renewable energy predictions: Clear understanding of wind speeds, water levels in damps, or underground thermal activity provide information for renewable energy decisions.\n",
    "\n",
    "- Predicting extreme events: extreme events like storms and floods are usually modeled and predicted to incorporate action plans.\n",
    "\n",
    "- Policy making: for example pollution concentrations measurements in the air can help the design of guidelines for industry contaminants. \n",
    "\n",
    "Examples of modeling flow data:\n",
    "\n",
    "- Forward prediction: simulate (propogate) distributions, including variation in time\n",
    "- Hindcasting (backtracking): where did this object initially come from?\n",
    "\n",
    "<img alt=\"Flow Example\" src=\"assets/flow_example.png\" width=\"300\">\n",
    "\n",
    "*Example: Malaysian Airlines Flight 370*\n",
    "\n",
    "<img alt=\"MH370\" src=\"assets/MH370.png\" width=\"300\">\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Spatial Correlation**\n",
    "\n",
    "Typically metrics are highly correlated when pair distances are small. For example, temperature patterns between two relatively close locations would be likely similar. \n",
    "\n",
    "$\\therefore$ Intuition: Correlation is a function of distance. How do we then estimate metrics in other locations?\n",
    "\n",
    "Given temperature (*or other measurements*) of a particular location and the covariance matrix between a pair of locations, how do we derive the conditional distribution of the temperature at another location?\n",
    "\n",
    "<img alt=\"Conditional Distribution of a Multivariate Normal\" src=\"assets/conditional_multivariate_normal.jpg\" width=\"300\">\n",
    "\n",
    "Model each location as a Gaussian random variable and formulate a multivariate Gaussian, $X \\sim N(\\mu_k, \\Sigma_k)$\n",
    "\n",
    "The PDF of a multivariate Gaussian RV, $p(x | \\mu, \\Sigma) = \\frac{1}{(2\\pi^{n/2}) \\lvert \\Sigma \\rvert^{1/2}} \\exp (-\\frac{1}{2} (x - \\mu)^T \\Sigma^{-1} (x - \\mu))$\n",
    "\n",
    "where $\\mu = \\mathbb {E}[X]$, $\\lvert \\Sigma \\rvert^{1/2}$ denotes the determinant of the covariance matrix $\\Sigma$\n",
    "\n",
    "Properties of the covariance operator:\n",
    "- $\\textsf{Cov}(X,X) = \\sigma _ X^2$\n",
    "- $\\textsf{Cov}(aX + bY,cW +dV) = ac*\\textsf{Cov}(X,W)+ad*\\textsf{Cov}(X,V)+bc*\\textsf{Cov}(Y,W)+bd*\\textsf{Cov}(Y,V)$\n",
    "\n",
    "A 2-dimensional Multivariate Gaussian PDF as an example:\n",
    "\n",
    "$\n",
    "\\displaystyle  p\\left( \\begin{bmatrix}  {x}_1 \\\\ {x}_2 \\end{bmatrix} \\mid \\begin{bmatrix}  \\mu _1\\\\ \\mu _2 \\end{bmatrix} , \\begin{bmatrix}  {\\sigma }_{11} &  {\\sigma }_{12} \\\\ {\\sigma }_{21} &  {\\sigma }_{22} \\end{bmatrix} \\right) =\\frac{1}{2\\pi ( {\\sigma }_{11}{\\sigma }_{22} -{\\sigma }_{12}{\\sigma }_{21} )^{1/2}} \\exp \\left(-\\frac{1}{2}\\left( \\begin{bmatrix}  {x}_1 \\\\ {x}_2 \\end{bmatrix} - \\begin{bmatrix}  \\mu _1\\\\ \\mu _2 \\end{bmatrix} \\right) ^\\intercal \\begin{bmatrix}  {\\sigma }_{11} &  {\\sigma }_{12} \\\\ {\\sigma }_{21} &  {\\sigma }_{22} \\end{bmatrix} ^{-1}\\left( \\begin{bmatrix}  {x}_1 \\\\ {x}_2 \\end{bmatrix} - \\begin{bmatrix}  \\mu _1\\\\ \\mu _2 \\end{bmatrix} \\right)\\right).\n",
    "$\n",
    "\n",
    "\n",
    "The conditional expectation of $\\mu_{A|B}$ is equal to $\\mu_A + \\frac{\\sigma_{AB}}{\\sigma_B^2} (y_B - \\mu_B)$ and $\\therefore$ the conditional expectation shifts by the correlation between the pair\n",
    "\n",
    "The conditional variance reduces given that we know a related variable which gives us more information about the estimate, $\\sigma_{A|B}^2 = \\sigma_A^2 - \\sigma_{AB} \\sigma_{B}^{-2} \\sigma_{AB}$\n",
    "\n",
    "****\n",
    "\n",
    "*Checkpoint: Look at `05b-spatial-prediction.ipynb` before proceeding further*\n",
    "\n",
    "****\n",
    "**Gaussian Process: Setup**\n",
    "\n",
    "Given a pair of multivariate Gaussian random variables, $X_1 \\in \\mathbb{R}^d$, and $X_2 \\in \\mathbb{R}^{N-d}$ where $X_1$ are cities where we do not have measurements and $X_2$ are cities where we have measurements. $\\mu_1$ and $\\mu_2$ are available.\n",
    "\n",
    "The random variables associated with physical locations represented by the variables $Z_1 \\in \\mathbb{R}^{M \\times d}$ and $Z_2 \\in \\mathbb{R}^{M \\times (N-d)}$ where $M = 2$ is typical for spatial data.\n",
    "\n",
    "Given a covariance function $k(z_i, z_j)$ that serves as a proxy for the relationship between two random variables as a function of their spatial locations. The kernel function is used to construct a covariance matrix, $\\Sigma_{ij} = cov(X_i, X_j) = k(z_i, z_j)$\n",
    "\n",
    "$\\displaystyle  \\mathbf{\\Sigma } = \\begin{bmatrix}  \\mathbf{\\Sigma }_{11} \\in \\mathbb {R}^{d\\times d} &  \\mathbf{\\Sigma }_{12} \\in \\mathbb {R}^{d \\times (N-d)}\\\\ \\mathbf{\\Sigma }_{21} \\in \\mathbb {R}^{(N-d) \\times d} &  \\mathbf{\\Sigma }_{22} \\in \\mathbb {R}^{(N-d) \\times (N-d)} \\end{bmatrix}$\n",
    "\n",
    "The distribution of the random variable $X_1$ conditioned on $X_2 = x_2$ is a normal distribution with:\n",
    "\n",
    "$\\mu_{X_1 \\vert X_2} = \\mu_1 + \\Sigma_{12} \\Sigma_{22}^{-1} (x_2 - \\mu_2)$\n",
    "\n",
    "$\\Sigma_{X_1 \\vert X_2} = \\Sigma_{11} - \\Sigma_{12} \\Sigma_{22}^{-1} \\Sigma_{21}$\n",
    "\n",
    "****\n",
    "\n",
    "**Model Selection in Gaussian Processes**\n",
    "\n",
    "Two ways to select kernel functions:\n",
    "\n",
    "1. Estimate generalization error with cross-validation, leave-one-out or k-fold\n",
    "\n",
    "    Given data $(x_1, y_1), \\dots, (x_N, y_N)$:\n",
    "    - For each $i$, remove $(x_i, y_i)$ from the data and fit a Gaussian Process to the rest (*leave-one-out*)\n",
    "    - Test the fitted Gaussian Process on the removed data point, predict $\\mu_{*}$, $\\sigma_{*}$\n",
    "    - Repeat for all $i$ data points and compute the average probability for a given $\\theta$\n",
    "    - Maximize $\\log p(y_i | X, y, \\theta) = -\\frac{1}{2} \\log \\sigma_{*}^2 - \\frac{(y_i - \\mu_{*})^2}{2\\sigma{*}^2} - \\frac{1}{2} \\log 2 \\pi$\n",
    "    - Choose $\\theta$ such  that it maximizes the log predictive probability\n",
    "    \n",
    "        $\\max \\sum_{i=1}^{N} \\log p(y_i | X, y_{-i}, \\theta)$\n",
    "        \n",
    "\n",
    "2. Maximize log likelihood of the data, $p(y | X, \\theta)$\n",
    "\n",
    "    - Trades off data fit and complexity\n",
    "    \n",
    "        $\\log p(y | X, \\theta) = - \\frac{1}{2} y^T K^{-1} y  - \\frac{1}{2} \\log \\vert K \\vert - \\frac{n}{2} \\log 2 \\pi$\n",
    "        \n",
    "        where \n",
    "        \n",
    "        - $\\vert K \\vert$ is the determinant of the covariance matrix\n",
    "        - $- \\frac{1}{2} y^T K^{-1} y$ is the data fit\n",
    "        - $- \\frac{1}{2} \\log \\vert K \\vert$ is the complexity penalty\n",
    "        \n",
    "    <img alt=\"Model Selection\" src=\"assets/model_selection.jpg\" width=\"600\">\n",
    "    \n",
    "    <img alt=\"Two Parameter Model Selection\" src=\"assets/two_parameter_selection.jpg\" width=\"600\">\n",
    "\n",
    "****\n",
    "\n",
    "**Long-range Climate Correlations**\n",
    "\n",
    "- Idea: Build a graph $G = (V, E)$, where $V$ is a set of nodes $(v_1, \\dots, v_n)$ and $E \\subseteq V \\times V$ is a set of edges such that $(v_i, v_j) \\in E$ implies that nodes $v_i$ and $v_j$ are connected, to represent long-range relationships (*correlations that is not due to physical closeness*) between points\n",
    "- Construction\n",
    "    - Nodes, $v_i$, spatial grid points, each has a time series\n",
    "    - Create an edge, $(v_i, v_j)$, if time series $y(i)$, $y(j)$ are sufficiently correlated; $\\vert r(y(i), y(j)) \\vert > threshold$\n",
    "    - Preprocess the data by removing seasonal variation, $y_{mt} (i) = \\frac{y_{mt}' (i) - \\bar y_m' (i)}{s(y_m'(i))}$, where $\\bar y_m' (i)$ could be the expected seasonal forecast of $y_{mt}' (i)$\n",
    "    - Network analysis on completed graph: *degree distribution, clustering coefficient, centrality*\n",
    "        - e.g. What is the fraction of the total global area to which a geography is connected? (\"degree\")\n",
    "\n",
    "\n",
    "Question: Given an region of interest, how do we define the set of edges between nodes?\n",
    "\n",
    "Assume we have a time series of data available for the variable we are interested in, such as temperature or pressure. We will define an edge between two nodes by identifying some predefined relationships between the two time-series defined at the two nodes if they have \"something to do with each other\". \n",
    "\n",
    "For example, one can compute the correlation between the two time-series and add an edge between the two points if they are sufficiently correlated, whereby *sufficiently* refers to a certain, prescribed threshold.\n",
    "\n",
    "The figure below shows a map where an edge was added between two points when it has generated measurements that were correlated more than certain prescribed threshold. The image shows that the area on the equator is a band with higher degree nodes, whereas areas outside the equator have lower degrees with some exceptions. This implies that areas near the equator have a much higher correlation with other areas.\n",
    "\n",
    "<img alt=\"Equator Graph Network\" src=\"assets/images_degree.png\" width=\"600\">\n",
    "\n",
    "Another analysis we can do on networks built from correlations on time-series data is to explore the relationship between physical distance and # of nodes.\n",
    "\n",
    "<img alt=\"Distance Distribution\" src=\"assets/images_timevar.png\" width=\"600\">\n",
    "\n",
    "****\n",
    "\n",
    "**Covariances are linear dependencies, how about non-linear dependencies?**\n",
    "\n",
    "Correlation between two random variables may $= 0$ but does not imply zero dependence.\n",
    "\n",
    "Mutual information, $I(Y_1, Y_2) = H(Y_1) - H(Y_1 \\vert Y_2)$, is the idea of detecting statistical dependence between two variables where $H(Y_1)$ indicates the uncertainty associated with the variable $Y_1$ and $H(Y_1 \\vert Y_2)$ is the uncertainty associated with $Y_1$ given that we know $Y_2$.\n",
    "\n",
    "If knowing $Y_2$ does not give us information about $Y_1$ then $I(Y_1, Y_2) = 0$ and on the opposite end, $I(Y_1, Y_2)$ will be large if there is large dependencies between $Y_1$ and $Y_2$ as $H(Y_1 \\vert Y_2)$ is small as $Y_2$ gives plenty of information about $Y_1$ and our uncertainty about $Y_1$ reduces.\n",
    "\n",
    "- Mutual information is zero, if and only if $Y_1, Y_2$ are independent\n",
    "- Edge between $v_i, v_j$ if mutual information $\\geq \\tau$\n",
    "\n",
    "Quantifying uncertainty: **entropy**\n",
    "\n",
    "- Discrete entropy as an examples\n",
    "\n",
    "    Entropy of one variable: $H(Y) = \\sum_{y \\in Y} p(y) \\log \\frac{1}{p(y)} = - \\sum_{y \\in Y} p(y) \\log p(y)$\n",
    "    \n",
    "    Joint entropy of two variables: $H(Y, Z) = - \\sum_{y \\in Y} \\sum_{z \\in Z} p(y, z) \\log p(y, z) \\leq H(Y) + H(Z)$\n",
    "    \n",
    "    Conditional entropy of two variables: $H(Y \\vert Z) = H(Y, Z) - H(Z)$\n",
    "    \n",
    "    - Symmetric quality: $I(Y, Z) = H(Y) - H(Y \\vert Z) = H(Z) - H(Z \\vert Y)$\n",
    "    - Captures non-linear relationships: $I(Y, Z) = 0$ if and only if independence\n",
    "    - Always non-negative, because \"information never hurts\": $H(Y) \\geq H(Y \\vert Z)$\n",
    "    \n",
    "    $I(Y, Z) = \\sum_{y, z} p(y, z) \\log \\frac{p(y, z)}{p(y) \\cdot p(z)}$\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic code\n",
    "A `minimal, reproducible example`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Question 1_\n",
    "\n",
    "Assume the temperature in City 1 $X_1$ is a Gaussian random variable with mean $\\mu_1 = 60$ and $\\sigma_1 = 10$, and that the temperature of City 2 is $X_2$ is a Gaussian random variable with mean $\\mu_2 = 90$ and $\\sigma_2 = 20$. Moreover, we know that the covariance between $X_1$ and $X_2$ is 100. Today, we have observed that the temperature in City 2 is 75. What is the probability that the new temperature in the City 1 is bigger than 56.25?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.25\n"
     ]
    }
   ],
   "source": [
    "# Compute conditional expectation\n",
    "mu_1, sigma_1 = 60, 10\n",
    "mu_2, sigma_2 = 90, 20\n",
    "cov = 100\n",
    "observed_2 = 75\n",
    "\n",
    "conditional_mu = mu_1 + cov/(sigma_2**2) * (observed_2 - mu_2)\n",
    "print(conditional_mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question 2*\n",
    "\n",
    "Let $p(x) = 0.25$ for $x \\in X = [1,2,3,4]$\n",
    "\n",
    "Compute the entropy of this distribution in bits ($\\log_2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "# Compute entropy of the distribution, H(X)\n",
    "import numpy as np\n",
    "p = 0.25\n",
    "X = np.array([1,2,3,4])\n",
    "\n",
    "h_X = np.sum([-p*np.log2(p) for _ in X])\n",
    "print(h_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question 3*\n",
    "\n",
    "Let $p(x, y)$ be a joint distribution over $x \\in [0, 1]$ and $y \\in [0,1]$ such that:\n",
    "\n",
    "$p(0,0) = 0.5$\n",
    "\n",
    "$p(0,1) = 0$\n",
    "\n",
    "$p(1,0) = 0.25$\n",
    "\n",
    "$p(1,1) = 0.25$\n",
    "\n",
    "Compute the entropy of this distribution in bits ($\\log_2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n"
     ]
    }
   ],
   "source": [
    "# Compute the entropy of the distribution\n",
    "\n",
    "p_XY = np.array([0.5, 0, 0.25, 0.25])\n",
    "h_XY = np.sum([-p * np.log2(p) for p in p_XY if p != 0])\n",
    "\n",
    "print(h_XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6887218755408672\n"
     ]
    }
   ],
   "source": [
    "# Compute the conditional entropy of the distribution\n",
    "\n",
    "p_Y = np.array([0.75, 0.25])\n",
    "h_Y = np.sum([-p*np.log2(p) for p in p_Y])\n",
    "h_X_givenY = h_XY - h_Y\n",
    "\n",
    "print(h_X_givenY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12255624891826566\n"
     ]
    }
   ],
   "source": [
    "# Compute the mutual information of X and Y\n",
    "## I(X,Y) = H(X) - H(X|Y) = H(Y) - H(Y|X)\n",
    "\n",
    "p_X = np.array([0.5, 0.5])\n",
    "h_X = np.sum([-p*np.log2(p) for p in p_Y])\n",
    "I_XY = h_X - h_X_givenY\n",
    "\n",
    "print(I_XY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question 4*\n",
    "\n",
    "Given a random variable $Z$ which can be $+1$ or $-1$ with equal probability and a random variable Y which can be $1$ or $2$ with equal probability. Now, define a new random variable $X = Y * Z$\n",
    "\n",
    "Compute the mutual information of $X$ and $Y$ in bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# X = [-2, -1, 1, 2] with equal probability\n",
    "# h_X = 2\n",
    "# h_Y = 1\n",
    "# h_XY = 2\n",
    "\n",
    "I_XY = 2+1-2\n",
    "print(I_XY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
